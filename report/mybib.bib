@ARTICLE{2017arXiv171201815S,                                                   
   author = {{Silver}, D. and {Hubert}, T. and {Schrittwieser}, J. and {Antonoglou}, I. and 
    {Lai}, M. and {Guez}, A. and {Lanctot}, M. and {Sifre}, L. and              
    {Kumaran}, D. and {Graepel}, T. and {Lillicrap}, T. and {Simonyan}, K. and  
    {Hassabis}, D.},                                                            
    title = "{Mastering Chess and Shogi by Self-Play with a General Reinforcement Learning Algorithm}",
  journal = {ArXiv e-prints},                                                   
archivePrefix = "arXiv",                                                        
   eprint = {1712.01815},                                                       
 primaryClass = "cs.AI",                                                        
 keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning},
     year = 2017,                                                               
    month = dec,                                                                
   adsurl = {http://adsabs.harvard.edu/abs/2017arXiv171201815S},                
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}                 
}

@article {Silver1140,
	author = {Silver, David and Hubert, Thomas and Schrittwieser, Julian and Antonoglou, Ioannis and Lai, Matthew and Guez, Arthur and Lanctot, Marc and Sifre, Laurent and Kumaran, Dharshan and Graepel, Thore and Lillicrap, Timothy and Simonyan, Karen and Hassabis, Demis},
	title = {A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play},
	volume = {362},
	number = {6419},
	pages = {1140--1144},
	year = {2018},
	doi = {10.1126/science.aar6404},
	publisher = {American Association for the Advancement of Science},
	abstract = {Computers can beat humans at increasingly complex games, including chess and Go. However, these programs are typically constructed for a particular game, exploiting its properties, such as the symmetries of the board on which it is played. Silver et al. developed a program called AlphaZero, which taught itself to play Go, chess, and shogi (a Japanese version of chess) (see the Editorial, and the Perspective by Campbell). AlphaZero managed to beat state-of-the-art programs specializing in these three games. The ability of AlphaZero to adapt to various game rules is a notable step toward achieving a general game-playing system.Science, this issue p. 1140; see also pp. 1087 and 1118The game of chess is the longest-studied domain in the history of artificial intelligence. The strongest programs are based on a combination of sophisticated search techniques, domain-specific adaptations, and handcrafted evaluation functions that have been refined by human experts over several decades. By contrast, the AlphaGo Zero program recently achieved superhuman performance in the game of Go by reinforcement learning from self-play. In this paper, we generalize this approach into a single AlphaZero algorithm that can achieve superhuman performance in many challenging games. Starting from random play and given no domain knowledge except the game rules, AlphaZero convincingly defeated a world champion program in the games of chess and shogi (Japanese chess), as well as Go.},
	issn = {0036-8075},
	URL = {http://science.sciencemag.org/content/362/6419/1140},
	eprint = {http://science.sciencemag.org/content/362/6419/1140.full.pdf},
	journal = {Science}
}

@ARTICLE{Browne12asurvey,
    author = {Cameron Browne and Edward Powley and Daniel Whitehouse and Simon Lucas and Peter I. Cowling and Stephen Tavener and Diego Perez and Spyridon Samothrakis and Simon Colton and et al.},
    title = {A survey of Monte Carlo tree search methods},
    journal = {IEEE TRANSACTIONS ON COMPUTATIONAL INTELLIGENCE AND AI},
    year = {2012}
}
